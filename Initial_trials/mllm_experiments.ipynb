{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1462fa634cf24b47bf07aa05783bcad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/950 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiden/anaconda3/envs/mllms-fairness/lib/python3.9/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ed2a723bb54a35a23516ec11a905bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/70.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9e7babbd9b40f6886c423dc57db43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acc23a81f7d4adc9790d560ae5597f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92cec42e20c4956b440652a8dc8273f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/2a/81/2a8151377370fd26d325522359e3eb5b8d8ff5ebe804b37283d1b6ec6b16bd6e/46df6c6e5fad297fe7fbca4963dcf180cb1d0528cabc884d1f603311fed01328?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00003.safetensors%3B+filename%3D%22model-00002-of-00003.safetensors%22%3B&Expires=1719663710&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTY2MzcxMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzJhLzgxLzJhODE1MTM3NzM3MGZkMjZkMzI1NTIyMzU5ZTNlYjViOGQ4ZmY1ZWJlODA0YjM3MjgzZDFiNmVjNmIxNmJkNmUvNDZkZjZjNmU1ZmFkMjk3ZmU3ZmJjYTQ5NjNkY2YxODBjYjFkMDUyOGNhYmM4ODRkMWY2MDMzMTFmZWQwMTMyOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=JGDAz%7EPxmSayUCo2v-L%7EQrhTNYj7xx8zGarf-JpQcekvjabFm65EbQ8EHUnoMVyoLcus4SoGXQSQmk13uv-uM4qHPEC26m7cNSrkhxjJwIa0n7TqAz5oImDwB2Z3levti2gLwSqOCSzeii%7ERasxHcuzJ87PkCuVDfPhOYscLsKxqCA39HNhNoDezyVgSFUXcGEA5dohVFC%7EZv2Kh5T9MWH3OGyWPSrzuErWm9j%7EnjggbR0DBBsuVBWSxaHyV-BYpN8JM%7EosX9NXF7MEbuyt%7EEClF29FMcbx4FdVxBgrqmGBsu8LVtr-llBqfgq9ulvYT2Bis-e6pwCtFSPN3U%7EeL3w__&Key-Pair-Id=K2FPYV99P2N66Q: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d70339de524c87955c8f0989a4ff49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:  21%|##        | 1.04G/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/2a/81/2a8151377370fd26d325522359e3eb5b8d8ff5ebe804b37283d1b6ec6b16bd6e/46df6c6e5fad297fe7fbca4963dcf180cb1d0528cabc884d1f603311fed01328?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00003.safetensors%3B+filename%3D%22model-00002-of-00003.safetensors%22%3B&Expires=1719663710&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTY2MzcxMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzJhLzgxLzJhODE1MTM3NzM3MGZkMjZkMzI1NTIyMzU5ZTNlYjViOGQ4ZmY1ZWJlODA0YjM3MjgzZDFiNmVjNmIxNmJkNmUvNDZkZjZjNmU1ZmFkMjk3ZmU3ZmJjYTQ5NjNkY2YxODBjYjFkMDUyOGNhYmM4ODRkMWY2MDMzMTFmZWQwMTMyOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=JGDAz%7EPxmSayUCo2v-L%7EQrhTNYj7xx8zGarf-JpQcekvjabFm65EbQ8EHUnoMVyoLcus4SoGXQSQmk13uv-uM4qHPEC26m7cNSrkhxjJwIa0n7TqAz5oImDwB2Z3levti2gLwSqOCSzeii%7ERasxHcuzJ87PkCuVDfPhOYscLsKxqCA39HNhNoDezyVgSFUXcGEA5dohVFC%7EZv2Kh5T9MWH3OGyWPSrzuErWm9j%7EnjggbR0DBBsuVBWSxaHyV-BYpN8JM%7EosX9NXF7MEbuyt%7EEClF29FMcbx4FdVxBgrqmGBsu8LVtr-llBqfgq9ulvYT2Bis-e6pwCtFSPN3U%7EeL3w__&Key-Pair-Id=K2FPYV99P2N66Q: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c20e3a08a14189b3891b52e2be15c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:  80%|########  | 3.97G/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75929c4a0fc401c94d86eac2daf291b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89104dc60433459886a49cbbe354d5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cda2550f434777b67b4bd2a6288f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3395d146468401794f45e8f0ba071d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12abcde399e3470bb20921b94fb96f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8505a2addd84a70a893aa2bde5f3e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2bbd05778a4781b26acd9e269e7327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6bf04ffd854f16ad5c4aa4d334b14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/41.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccbd9350b0d46e2a3853f82f6c21da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"USER:  \\nWhat's the content of the image? ASSISTANT: The image features a street scene with a stop sign, a red building,\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "\n",
    "prompt = \"USER: <image>\\nWhat's the content of the image? ASSISTANT:\"\n",
    "url = \"https://www.ilankelman.org/stopsigns/australia.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(**inputs, max_new_tokens=15)\n",
    "processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_llava():\n",
    "    llava_model = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "    llava_processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "    return llava_model, llava_processor\n",
    "\n",
    "def load_image(filepath):\n",
    "    image = Image.open(filepath)\n",
    "    return image\n",
    "\n",
    "def obtain_caption(model, processor, prompt, image):\n",
    "    \n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "    generate_ids = model.generate(**inputs, max_new_tokens=15)\n",
    "    return processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_model, llava_processor = obtain_llava()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllms-fairness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
